{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pickle\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'bf-titanic-model'\n",
    "SCRIPT_PATH = '/titanic-sagemaker-inference/titanic_featurizer.py'\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess input data\n",
    "def predict_fn(input_data, model):\n",
    "    \n",
    "    features = model.transform(input_data)\n",
    "\n",
    "    if label_column in input_data:\n",
    "        # Return the label (as the first column) and the set of features.\n",
    "        return np.insert(features, 0, input_data[label_column], axis=1)\n",
    "    else:\n",
    "        # Return only the set of features\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize fitted model\n",
    "def model_fn(model_dir):\n",
    "    preprocessor = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model from S3\n",
    "s3 = boto3.resource('s3')\n",
    "obj = s3.Object(BUCKET, 'v1/model/trained_model.pickle')\n",
    "body = obj.get()['Body'].read()\n",
    "inference_model = pickle.loads(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'inference-pipeline-' + timestamp_prefix\n",
    "endpoint_name = 'inference-pipeline-ep-' + timestamp_prefix\n",
    "prod_model = PipelineModel(\n",
    "    name=model_name, \n",
    "    role=role,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    models=inference_model)\n",
    "\n",
    "sklearn_preprocessor.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Transform Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a SKLearn Transformer from the trained SKLearn Estimator\n",
    "transformer = sklearn_preprocessor.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type='ml.m4.xlarge',\n",
    "    assemble_with = 'Line',\n",
    "    accept = 'text/csv')\n",
    "\n",
    "# Preprocess training input\n",
    "transformer.transform(train_input, content_type='text/csv')\n",
    "print('Waiting for transform job: ' + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()\n",
    "preprocessed_train = transformer.output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
